---
layout:     post
title:      QJUMP NSDI 2015
subtitle:   Queues Don’t Matter When You Can JUMP Them!
date:       2019-7-14
author:     Yiran
header-img: img/post-bg-bridge.jpg
catalog: true
tags:
    - Transport in Datacenter
---

## [Queues Don’t Matter When You Can JUMP Them! (best paper)](https://www.cl.cam.ac.uk/research/srg/netos/qjump/pubs/2015-nsdi-qjump.pdf)


### 核心思想

rate limiting 与 priority value 相结合, 来保证 latency


### Motivation

解决数据中心网络中 network interference 问题: congestion from throughput-intensive applications causes queueing that delays traffic from latency-sensitive applications. 

实际上与DCTCP解决的问题有相似之处, latency来自于排队, 而大流占据队列使得小流的排队长, DCTCP通过减小queue长度来降低latency, 采用per-flow的拥塞控制+switch的ECN标记. QJUMP从应用的角度解决network interference来保证latency

<img width="650" height="450" src="/img/post-qjump-1.png"/>


### Design

- **Single Switch Service Model**

  <img width="450" height="450" src="/img/post-qjump-2.png"/>

  $$
  worst \ case \ end-to-end \ delay  <= n \times \frac{P}{R} + \epsilon
  $$

  $P$ the maximum packet size (in bits), $R$ is the rate of the slowest link in bits per second and $\epsilon$ is the cumulative processing delay introduced by switch hops.


- **Network epochs**

  A network epoch is the maximum time that an idle network will take to service one packet from every sending host, regardless of the source, destination or timing of those packets. 

  ```每个host一个epoch只发一个包, 就能有latency的bound.``` 由于时钟不同步，放宽后一个epoch应当是worst case end-to-end delay的两倍.

  $$
  network \ epoch  = 2n \times \frac{P}{R} + \epsilon
  $$


- **QJUMP level**

  如果按照上式的所有host每个epoch发一个包, 随着host数目增多, 吞吐会下降. 对吞吐敏感的应用不友好.

  $$
  throughput = \frac{P}{network \ epoch} \approx \frac{R}{2n}
  $$


  然而, 不同的应用对latency要求不同, 并且实际情况下, 不可能所有的host同时向一个目的端口发数据. 通过引入一个 factor $f$, 根据不同的应用放宽host的数目, 也就是引入QJUMP level. $f$ is a “throughput factor”: as the value of $f$ grows, so does the amount of bandwidth available.

  $$
  n^{'} = \frac{n}{f}
  $$

  $f = 1$时, 一个epoch能发1个包保证latency; $f = n$时, 一个epoch能发$n$个包保证throughput. QJUMP level利用网络支持的优先级实现: For each priority, assign a distinct value of $f$ , with higher priorities receiving smaller values. Since a small value of $f$ implies an aggressive rate limit, priorities become useful because they are no longer “free”.


### Experiments
- Testbed
- Simulation

  $P = 9kB$, $n = 144$, {$f0$... $f7$} = {144,100,20,10,5,3,2,1}

  <img width="750" height="650" src="/img/post-qjump-3.png"/>


### Thoughts

QJUMP实际上是对不同的优先级, 实施不同的速率limit. ```高优先级的速率控制应当比低优先级的速率控制更加aggressive.``` 

在端进行rate limit实际上把网络中的排队一部分转移到了端的socket buffer中 (QJUMP resizes socket buffers to apply early back-pressure).

实验结果中QJUMP比pfabric有的指标好, 说明了端速率控制的必要性？

优先级是针对应用的, 四层以上的, QJUMP解决的也是应用 interface的问题. DCTCP针对三层, 更加底层, 解决小流排队长





